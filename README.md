# AI HSR Risk Reference Tool v2.0

**Quick Reference Risk Identification and Mitigation Guide for IRBs Reviewing AI in Human Subjects Research**

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

---

## üéØ Purpose

This tool assists Institutional Review Boards (IRBs) and Ethics Committees in identifying and addressing AI-specific risks in human subjects research. It complements standard IRB review processes by providing structured guidance on risks unique to artificial intelligence and machine learning systems.

**Key Features:**
- ‚úÖ Structured around the **3-Phase AI HSR IRB Review Framework**
- ‚úÖ Evidence-based: Built on MIT AI Risk Repository, ISO 14971, and U.S. regulatory frameworks
- ‚úÖ Practical guidance with reviewer prompts and mitigation strategies
- ‚úÖ Validated at 23+ institutions with 21% improvement in reviewer confidence
- ‚úÖ Interactive filtering by development phase, risk domain, and specific risk type

---

## üöÄ Quick Start

### Option 1: Use Online (Recommended)
Visit the live tool: **[https://etotamiko.github.io/ai-hsr-risk-tool/]

### Option 2: Download and Use Locally
1. Download `index.html` from this repository
2. Open in any modern web browser
3. No installation required - works offline!

### Option 3: Host on Your Own Server
1. Clone this repository
2. Upload `index.html` to your web server
3. Access via your institution's domain

---

## üìñ What's Included

### Interactive Sections
1. **Overview** - Introduction and key AI-specific risks
2. **3-Phase Framework** - Development phase-based review approach
3. **Risk Domains** - Four MIT AI risk domains relevant to HSR
4. **Interactive Tool** - Filter and explore 12+ risk scenarios
5. **Definitions** - Key terms, model types, and regulatory frameworks
6. **About** - Methodology, validation results, and citations

### Risk Coverage
- **12 Pre-loaded Risk Scenarios** including:
  - Algorithmic bias in training data
  - Model opacity and explainability
  - Misclassification and clinical error
  - Data privacy and re-identification
  - Automation bias and over-reliance
  - AI hallucinations and fabricated information
  - And more...

### Each Risk Includes:
- Clear description of the concern
- Applicable development phases
- Relevant risk domains
- Concrete mitigation strategies
- Phase-specific reviewer prompts

---

## üéì How to Use This Tool

### For IRB Reviewers:
1. Navigate to the **Interactive Tool** section
2. Select the development phase of the AI system under review
3. Choose relevant risk domains
4. Review identified risks, mitigation strategies, and reviewer prompts
5. Use prompts to guide IRB deliberations
6. Document findings in your IRB review materials

### For Researchers:
- Use this tool to anticipate IRB concerns
- Proactively address AI-specific risks in protocols
- Reference mitigation strategies in study design
- Improve protocol quality and reduce revision cycles

### For Training:
- Use as a teaching tool for IRB members
- Reference in AI research ethics courses
- Guide development of institutional AI review policies

---

## üî¨ Methodology

The tool maps risks and safeguards from authoritative sources against U.S. regulatory frameworks:

**Risk Sources:**
- MIT AI Risk Repository
- MIT AI Risk Mitigation Library
- ISO 14971 (risk management for medical devices)

**Regulatory Alignment:**
- 45 CFR 46 (Common Rule)
- 21 CFR Parts 56, 312, 812, 820 (FDA regulations)
- 21 CFR Part 11 (electronic records)
- HIPAA Privacy Rule
- Belmont Principles
- Good Clinical Practice (GCP)

---

## üÜì License & Usage

### Non-Commercial Use (FREE)
This tool is **FREE for:**
- ‚úÖ IRB review and research oversight
- ‚úÖ Educational institutions
- ‚úÖ Non-profit research organizations
- ‚úÖ Academic medical centers
- ‚úÖ Training and education
- ‚úÖ Personal/institutional use

### Licensing
**Dual-licensed for maximum protection:**
- **Code (HTML/CSS/JS):** AGPL-3.0 - Prevents commercialization
- **Content/Documentation:** CC BY-NC-SA 4.0 - Non-commercial use only

**Key Requirements:**
- ‚úì Provide attribution to Tamiko Eto and TechInHSR
- ‚úì Share modifications under same license
- ‚úì No commercial use without permission
- ‚úì Indicate if changes were made

See [LICENSE.md](LICENSE.md) for complete terms.

### Commercial Use
For commercial licensing inquiries, contact: techinhsr.com

---

## üìö Citation

If you use this tool in your work, please cite:

```bibtex
@software{eto2025aihsr,
  author = {Eto, Tamiko},
  title = {AI HSR Risk Reference Tool v2.0: Quick Reference Risk 
           Identification and Mitigation Guide for IRBs Reviewing 
           AI in Human Subjects Research},
  year = {2025},
  publisher = {TechInHSR},
  url = {https://github.com/etotamiko/ai-hsr-risk-tool},
  note = {Licensed under AGPL-3.0 and CC BY-NC-SA 4.0}
}
```

---

## üîÑ Version History

### v2.0 (December 2025) - Current
- Complete redesign as interactive web application
- Enhanced filtering and navigation
- 12 pre-loaded risk scenarios
- Mobile-responsive design
- Single-file HTML for easy deployment

### v1.5 (September 2024)
- Excel spreadsheet version
- Glide webapp prototype
- Beta testing with 20+ institutions
- Initial validation results

---

## üõ†Ô∏è Technical Details

**Built With:**
- Pure HTML5, CSS3, and JavaScript
- No external dependencies (except Google Fonts)
- Works in all modern browsers
- Mobile-responsive design
- Accessible (WCAG 2.1 AA compliant)

**Browser Support:**
- Chrome/Edge (latest)
- Firefox (latest)
- Safari (latest)
- Mobile browsers (iOS/Android)

---

## ü§ù Contributing

We welcome contributions from the IRB and AI ethics community!

### How to Contribute:
1. Fork this repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Make your changes
4. Commit with clear messages (`git commit -m 'Add risk scenario for XYZ'`)
5. Push to the branch (`git push origin feature/AmazingFeature`)
6. Open a Pull Request

### Contribution Ideas:
- Add new risk scenarios
- Improve mitigation strategies
- Enhance reviewer prompts
- Add international regulatory frameworks
- Translate to other languages
- Report bugs or usability issues

---

## üîÆ Roadmap

### Planned for v2.1:
- [ ] Additional risk scenarios (target: 20+ total)
- [ ] Export functionality (PDF, Word)
- [ ] Custom risk scenario builder
- [ ] Institution-specific customization options

### Planned for v3.0:
- [ ] Integration with IRB electronic systems
- [ ] EU AI Act and GDPR compliance guidance
- [ ] ISO 42001, 23894, 42005, 24368 alignment
- [ ] Patient and community perspective integration
- [ ] Multi-language support

---

## üìû Contact & Support

**Author:** Tamiko Eto, MA CIP  
**Organization:** TechInHSR  
**Email:** tamiko@techinhsr.com  
**Website:** [https://techinhsr.com](https://techinhsr.com)  
**Blog:** [https://techinhsr.com/blog](https://techinhsr.com/blog)

### Get Help:
- üìß Email: techinhsr.com
- üêõ Report Issues: [GitHub Issues](https://github.com/etotamiko/ai-hsr-risk-tool/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/etotamiko/ai-hsr-risk-tool/discussions)

---

## üôè Acknowledgements

Special thanks to:
- **Professor Josep Curto, PhD** - Center for AI Safety (CAIS) for invaluable guidance
- **Mark Lifson** - Collaborators on the 3-Phase Framework
- **Beta Testing Participants** - 23+ institutions who provided critical feedback
- **MIT FutureTech** - For the AI Risk Repository and Mitigation Library
- **IRB Community** - For ongoing support and validation

---

## üìÑ Related Resources

- **Original Excel Version:** [GitHub - TechInHSR](https://github.com/etotamikolab/TechInHSR)
- **Glide App v1.5:** [ai-hsr-risk-reference.glide.page](https://ai-hsr-risk-reference.glide.page)
- **Blog Post:** [TechInHSR.com Announcement](https://techinhsr.com/2025/09/04/announcing-the-ai-hsr-risk-reference-tool)
- **Published Framework:** [Stanford Digital Repository](https://purl.stanford.edu/zj025zw1714)

---

## ‚öñÔ∏è Disclaimer

This tool is provided for educational and informational purposes. It does not constitute legal, regulatory, or medical advice. IRBs should use this tool as a supplement to, not a replacement for, comprehensive protocol review and institutional policies. Always consult with qualified experts and follow applicable regulations.

---

**Made with ‚ù§Ô∏è for the IRB and AI Ethics Community**

*Protecting human subjects in the age of artificial intelligence*
